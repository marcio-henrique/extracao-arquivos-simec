{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vGsldHTYAbYS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from request_simec import login, get_url, post_url\n",
    "from restrictions import exemplares_aceitos, formatos_aceitos\n",
    "\n",
    "import zipfile\n",
    "from PyPDF2 import PdfFileReader\n",
    "from pathlib import Path\n",
    "\n",
    "import hashlib\n",
    "import math\n",
    "import shutil\n",
    "import unidecode\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dos Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "8DPHUGxeRrj1"
   },
   "outputs": [],
   "source": [
    "#arquivo inicial extraído diretamente do site do simec\n",
    "df = pd.read_csv(\n",
    "         'dados/TODOS.csv',\n",
    "         dtype=str\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_simec ():\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36'}\n",
    "    s = requests.Session()\n",
    "    s.get(get_url)\n",
    "    s.post(post_url, data=login)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = login_simec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_reds_simec():\n",
    "    for index, row in df.iterrows():\n",
    "    #condição para o arquivo ser baixado\n",
    "    if (row['Formato'] in formatos_aceitos) and (row['Exemplar'] in exemplares_aceitos):\n",
    "        df.at[index, 'Deve ser baixado'] = 'Sim'\n",
    "        df.at[index, 'Baixado'] = 'Não'\n",
    "\n",
    "        #verificar head do arquivo no servidor\n",
    "        header = s.head(row['Arquivo'])\n",
    "        df.at[index, 'Header'] = header.headers\n",
    "    \n",
    "        #mapeando nome e extensão do arquivo via header\n",
    "        if \"content-disposition\" in header.headers.keys():\n",
    "            content_disposition = header.headers['content-disposition']\n",
    "            try:\n",
    "                f_name = re.findall(\"filename=(.+)\", content_disposition)[0]\n",
    "            except IndexError:\n",
    "                f_name = content_disposition      \n",
    "        else:\n",
    "            f_name = \"NO CONTENT-DISPOSITION\"\n",
    "            \n",
    "        if \"Content-Type\" in header.headers.keys():\n",
    "            content_type = header.headers['Content-Type']\n",
    "            try:\n",
    "                c_type = re.findall(\"application/(.+)\", content_type)[0]\n",
    "            except IndexError:\n",
    "                c_type = content_type\n",
    "        else:\n",
    "            c_type = \"NO CONTENT-TYPE\"\n",
    "            \n",
    "        df.at[index, 'Nome do Arquivo'] = f_name\n",
    "        df.at[index, 'Extensão do Arquivo'] = c_type\n",
    "        \n",
    "        print(row['id'] + ' ' + f_name + ' ' + c_type)\n",
    "\n",
    "    else:\n",
    "        df.at[index, 'Deve ser baixado'] = 'Não'\n",
    "        print(row['id'] + ' ****** ' + 'NÃO DEVE SER BAIXADO')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_reds() {\n",
    "    i = 1\n",
    "    for index, row in df.iterrows():  \n",
    "        if (row['Deve ser baixado'] == 'Sim') and (row['Baixado'] == 'Não'):\n",
    "            print(str(i) + ' - ' + row['id'] + ' ' + row['Nome do Arquivo'] + ' ' + row['Extensão do Arquivo'])\n",
    "\n",
    "            #Baixa o arquivo\n",
    "            try:\n",
    "                r = s.get(row['Arquivo'], headers=headers)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            print(r.headers)\n",
    "\n",
    "            #Propriedade que indica erro no arquivo baixado\n",
    "            if \"Content-Lenght\" in r.headers.keys():\n",
    "                print('Badly download')\n",
    "                continue\n",
    "\n",
    "            #Salva o arquivo localmente\n",
    "            filename = 'arquivos/' + row['Edital'] + '/' + row['id'] + '/' + row['Nome do Arquivo']\n",
    "            os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "\n",
    "            #Salva nos dados o estado de Baixado e de Verificar integridade\n",
    "            df.at[index, 'Baixado'] = 'Sim'\n",
    "            df.at[index, 'Integridade'] = 'Verificar'\n",
    "            df.to_csv('dados/TODOS.csv', index=False)\n",
    "            \n",
    "            print('BAIXADO!')            \n",
    "\n",
    "            #Evita que o servidor do MEC barre o download\n",
    "            time.sleep(2)\n",
    "            s.get(get_url)    \n",
    "            time.sleep(5)\n",
    "\n",
    "            i += 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_reds_simec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "collapsed": true,
    "id": "hdSZT6snJh2i",
    "outputId": "6e7cf224-041a-41db-d7e6-570ded105b02"
   },
   "outputs": [],
   "source": [
    "download_reds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração e mapeamento dos zips "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'dados/TODOS.csv',\n",
    "    dtype=str\n",
    ")\n",
    "\n",
    "arq_zip = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento do tamanho de cada arquivo e verificação se o arquivo é integro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_file_sizes (df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Baixado'] == 'Sim':\n",
    "            path = 'arquivos/' + row['Edital'] + '/' + row['id']\n",
    "            print(path);\n",
    "            get_size_file_in_kb(path, df, index)\n",
    "\n",
    "\n",
    "def get_size_file_in_kb(path, df, index):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.zip'):\n",
    "                \n",
    "                get_real_and_zipped_size_in_kb(path, df, index, file)\n",
    "            else:\n",
    "                get_size_file_in_kb(path, df, index, file)\n",
    "\n",
    "def get_size_file_in_kb(path, df, index, file):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if file.endswith('.pdf'):\n",
    "            valid_file = check_pdf_file(path + '/' + file)\n",
    "            if (valid_file):\n",
    "                df.at[index, 'Integridade'] = 'ok'\n",
    "                print (df.at[index, 'id'] + \" - OK\")\n",
    "            else:\n",
    "                df.at[index, 'Integridade'] = 'no a pdf file'\n",
    "                print (df.at[index, 'id'] + \" - BAD PDF\")\n",
    "                df.to_csv('dados/TODOS.csv', index = False)\n",
    "                continue\n",
    "                        \n",
    "        file_obj = Path(path + '/' + file)\n",
    "        size = file_obj.stat().st_size\n",
    "\n",
    "        size_kb = float(size) / 1000  # kB\n",
    "        print (df.at[index, 'id'] + \" - \" + str(size_kb))\n",
    "        df.at[index, 'Size'] = size_kb\n",
    "        df.to_csv('dados/TODOS.csv', index = False)\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "\n",
    "def get_real_and_zipped_size_in_kb(path, df, index, file):\n",
    "    try:\n",
    "        zfile = zipfile.ZipFile(path + '/' + file)\n",
    "        zipped_size = os.path.getsize(path + '/' + file)\n",
    "    except zipfile.BadZipfile as ex:\n",
    "        print (df.at[index, 'id'] + \" no a zip file: \" + ex)\n",
    "        df.at[index, 'Integridade'] = 'no a zip file'\n",
    "        continue\n",
    "    except:\n",
    "\n",
    "    #zip test\n",
    "    ret = zfile.testzip()\n",
    "    if ret is not None:\n",
    "        print (df.at[index, 'id'] + \" bad zip file, error: \" + ret)\n",
    "        df.at[index, 'Integridade'] = 'bad zip file'\n",
    "    else:\n",
    "        df.at[index, 'Integridade'] = 'ok'\n",
    "\n",
    "    real_size = sum([zinfo.file_size for zinfo in zfile.filelist])\n",
    "    real_size_kb = float(size) / 1000  # kB\n",
    "    zipped_size_kb = float(zipped_size) / 1000  # kB\n",
    "\n",
    "    print (df.at[index, 'id'] + \" - \" + str(zip_kb))\n",
    "    df.at[index, 'Size'] = real_size_kb\n",
    "    df.at[index, 'Zipped size'] = zipped_size_kb\n",
    "    df.to_csv('dados/TODOS.csv', index = False)\n",
    "\n",
    "\n",
    "def check_pdf_file(fullfile):\n",
    "    with open(fullfile, 'rb') as f:\n",
    "        try:\n",
    "            pdf = PdfFileReader(f)\n",
    "            info = pdf.getDocumentInfo()\n",
    "            if info:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_file_sizes (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarte de arquivos não integros/corrompidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_corrupted_files():\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if (row['Integridade'] != 'ok'):\n",
    "            file = 'arquivos/' + row['Edital'] + '/' + row['id'] + '/' + row['Nome do Arquivo']\n",
    "            print(row['Edital'] + '/' + row['id'])\n",
    "            print(row['Arquivo'])\n",
    "            i = i + 1\n",
    "            if os.path.exists(file):\n",
    "                os.remove(file)\n",
    "                print(\"Arquivo Removido\")\n",
    "            else:\n",
    "                print(\"The file does not exist\")\n",
    "\n",
    "            df.at[index, 'Baixado'] = 'Não'\n",
    "            df.to_csv('dados/TODOS.csv', index = False)\n",
    "            print('\\n\\n')\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_corrupted_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento dos Arquivos zip e seus metadados próprios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_files_in_zips (df, arq_zip):\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if (row['Baixado'] == 'Sim') and (row['Extensão do Arquivo'] in ['zip', 'x-zip-compressed']):\n",
    "            path = 'arquivos/' + row['Edital'] + '/' + row['id']\n",
    "#             print(path);\n",
    "            \n",
    "            i = get_all_files_in_zip(path, df, index, row['id'], arq_zip, i)\n",
    "\n",
    "\n",
    "def get_all_files_in_zip(path, df, index, df_row_id, arq_zip, i):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.zip'):\n",
    "                with zipfile.ZipFile(path + '/' + file, 'r') as zipObj:\n",
    "                    listOfiles = zipObj.infolist()\n",
    "#                     print(listOfiles)\n",
    "                    for elem in listOfiles:\n",
    "                        row = {}\n",
    "                        row['red_id'] = df_row_id\n",
    "                        row['nome'] = elem.filename.split(\"/\")[-1]\n",
    "                        row['tamanho'] = elem.file_size\n",
    "                        row['tamanho_zipado'] = elem.compress_size\n",
    "                        row['extensão'] = elem.filename.split(\".\")[-1]\n",
    "                        row['path'] = elem.filename\n",
    "                        print(str(i) + ' - ', end=\"\")\n",
    "                        print(row)\n",
    "                        arq_zip.loc[i] = row\n",
    "                        arq_zip.to_csv('dados/arquivos_zip.csv', index = False)\n",
    "        \n",
    "                        i = i + 1\n",
    "            else:\n",
    "                print('ERROR: ISNT ZIP')\n",
    "                \n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_files_in_zips (df, arq_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip dos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_all (df):\n",
    "    for index, row in df.iterrows():\n",
    "        if(row['Extensão do Arquivo'] in ['zip', 'x-zip-compressed']):\n",
    "#             print (row['id'] + ' - ' + row['Edital'])\n",
    "#             row['Nome do Arquivo']\n",
    "            path = 'arquivos/' + row['Edital'] + '/zip/' + row['id']\n",
    "#             path = row['id']\n",
    "            \n",
    "            with zipfile.ZipFile(path + '/' + row['Nome do Arquivo'], \"r\") as zip_ref:\n",
    "                zip_ref.extractall(path)\n",
    "            os.remove(path + '/' + row['Nome do Arquivo'])\n",
    "            \n",
    "            df.at[index, 'Unzip'] = 'ok'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_all(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padronização dos dados dos arquivos zip para os dados dos outros arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ren = arq_zip.rename(columns={'red_id': 'id', 'nome': 'Nome do Arquivo', 'tamanho': 'Size',\n",
    "                       'tamanho zipado': 'Zipped size', 'extensão': 'Extensão do Arquivo',\n",
    "                       'path': 'Caminho Local'})\n",
    "ren = ren[ren['Extensão do Arquivo'] != 'DS_Store']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserção dos metadados do zip nos arquivos descompactados do mesmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, row in df.iterrows():\n",
    "    if (row['Extensão do Arquivo'] in ['zip', 'x-zip-compressed']):\n",
    "        #print('rowz')\n",
    "        rows_zip = ren[ren['id'] == row['id']]\n",
    "        #print(rows_zip)\n",
    "        i = 1\n",
    "        for i_zip, r_zip in rows_zip.iterrows():\n",
    "            alter_dataframe_register(i_zip, row, r_zip, i)\n",
    "            i += 1\n",
    "\n",
    "def alter_dataframe_register(index, origin_row, destiny_row, i):\n",
    "    ren.at[index, 'Edital'] = origin_row['Edital']\n",
    "    ren.at[index, 'CNPJ Editora'] = origin_row['CNPJ Editora']\n",
    "    ren.at[index, 'Editora'] = origin_row['Editora']\n",
    "    ren.at[index, 'Código Coleção'] = origin_row['Código Coleção']\n",
    "    ren.at[index, 'Coleção'] = origin_row['Coleção']\n",
    "    ren.at[index, 'Código Volume'] = origin_row['Código Volume']\n",
    "    ren.at[index, 'Volume'] = origin_row['Volume']\n",
    "    ren.at[index, 'Componente'] = origin_row['Componente']\n",
    "    ren.at[index, 'Série'] = origin_row['Série']\n",
    "    ren.at[index, 'Formato'] = origin_row['Formato']\n",
    "    ren.at[index, 'Exemplar'] = origin_row['Exemplar']\n",
    "    ren.at[index, 'Tipo de Arquivo'] = origin_row['Tipo de Arquivo']\n",
    "    ren.at[index, 'Arquivo'] = origin_row['Arquivo']\n",
    "    ren.at[index, 'Header'] = origin_row['Header']\n",
    "    #ren.at[index, 'Header get()'] = origin_row['Header get()']\n",
    "    ren.at[index, 'Deve ser baixado'] = origin_row['Deve ser baixado']\n",
    "    ren.at[index, 'Baixado'] = origin_row['Baixado']\n",
    "    #ren.at[index, 'Extensão do Arquivo no Header'] = origin_row['Extensão do Arquivo no Header']\n",
    "    ren.at[index, 'Integridade'] = origin_row['Integridade']\n",
    "    ren.at[index, 'id_zip'] = i\n",
    "    print(ren.at[index, 'Edital'])\n",
    "\n",
    "\n",
    "def set_caminho_local():\n",
    "    for index, row in df.iterrows():\n",
    "        if (row['Formato'] in ['Digital', 'Audiovisual']):\n",
    "            if (type(row['id_zip']) is str):\n",
    "                #print('rowz')\n",
    "                rows_zip = ren[ren['id'] == row['id']]\n",
    "                #print(rows_zip)\n",
    "                for i_zip, r_zip in rows_zip.iterrows():\n",
    "                    if (r_zip['Nome do Arquivo'] != row['Nome do Arquivo']):\n",
    "                        continue\n",
    "\n",
    "                    print(r_zip['Nome do Arquivo'] + ' - ' + row['Nome do Arquivo'])\n",
    "                    df.at[index, 'Caminho Local'] = r_zip['Caminho Local']\n",
    "                    print (df.at[index, 'Caminho Local'])\n",
    "                    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_caminho_local()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cruzamento dos dados dos arquivos descompactados com os outros arquivos baixados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.concat([df, ren])\n",
    "m = m[(m['Extensão do Arquivo'] != 'zip') & (m['Extensão do Arquivo'] != 'x-zip-compressed')]\n",
    "\n",
    "ren.to_csv('dados/arquivos_zip.csv', index = False)\n",
    "m.to_csv('dados/TODOS.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'dados/TODOS.csv',\n",
    "    dtype=str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Edital'] == 'PNLD 2020 - Obras Didáticas - Anos Finais do Ensino Fundamental', ['edital sv']] =  'pnld_2020'\n",
    "df.loc[df['Edital'] == 'PNLD 2019 - ATUALIZAÇÃO BNCC - Educação Infantil e Anos Iniciais do Ensino Fundamental', ['edital sv']] =  'pnld_2019'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "teste simec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
