{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "from PyPDF2 import PdfFileReader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "         'dados/TODOS_sem_arquivos_separados.csv',\n",
    "         dtype=str,\n",
    "    )\n",
    "# arq_zip = pd.read_csv(\n",
    "#         'dados/arquivos_zip.csv',\n",
    "#         dtype=str,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tudao = pd.read_csv(\n",
    "     'dados/DADOS_CRUZADOS.csv',\n",
    "     dtype=str,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'pdf', 'zip', 'docx', 'mp4', 'mp3', 'DOCX'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Extensão do Arquivo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Plano_de_desenvolvimento_6o_ano_SESI_bimestre_1_OK_FNDE.pdf',\n",
       "       'Plano_de_desenvolvimento_6o_ano_bimestre_1_OK-corrigido_FNDE.pdf',\n",
       "       ..., 'COL1TITULO4_MP_4_MATEMATICA_DM_CORRIGIDO_FNDE.pdf',\n",
       "       'COL1TITULO5_MP_5_MATEMATICA_DM_CORRIGIDO_FNDE.pdf',\n",
       "       'COL1TITULO1_LP_4A5_PRE_ESCOLA_DM_FNDE.pdf'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Nome do Arquivo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dados/TODOS.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['docx', 'mp4', 'mp3', 'pdf', 'DOCX'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ren = arq_zip.rename(columns={'red_id': 'id', 'nome': 'Nome do Arquivo', 'tamanho': 'Size',\n",
    "                       'tamanho zipado': 'Zipped size', 'extensão': 'Extensão do Arquivo',\n",
    "                       'path': 'Caminho Local'})\n",
    "ren = ren[ren['Extensão do Arquivo'] != 'DS_Store']\n",
    "ren['Extensão do Arquivo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df['Extensão do Arquivo no Header'] == 'text/html; charset=ISO-8859-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row', 'id', 'Edital', 'CNPJ Editora', 'Editora', 'Código Coleção',\n",
       "       'Coleção', 'Código Volume', 'Volume', 'Componente', 'Série', 'Formato',\n",
       "       'Exemplar', 'Tipo de Arquivo', 'Arquivo', 'Header', 'Header get()',\n",
       "       'Nome do Arquivo', 'Extensão do Arquivo', 'Deve ser baixado', 'Baixado',\n",
       "       'Caminho Local', 'Extensão do Arquivo no Header', 'Integridade', 'Size',\n",
       "       'Zipped size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Nome do Arquivo', 'Size', 'Zipped size', 'Extensão do Arquivo',\n",
       "       'Caminho Local'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ren.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for index, row in df.iterrows():\n",
    "#     if (row['Extensão do Arquivo'] in ['zip', 'x-zip-compressed']):\n",
    "#         #print('rowz')\n",
    "#         rows_zip = ren[ren['id'] == row['id']]\n",
    "#         #print(rows_zip)\n",
    "#         i = 1\n",
    "#         for i_zip, r_zip in rows_zip.iterrows():\n",
    "#             alter_dataframe_register(i_zip, row, r_zip, i)\n",
    "#             i += 1\n",
    "\n",
    "# def alter_dataframe_register(index, origin_row, destiny_row, i):\n",
    "#     ren.at[index, 'Edital'] = origin_row['Edital']\n",
    "#     ren.at[index, 'CNPJ Editora'] = origin_row['CNPJ Editora']\n",
    "#     ren.at[index, 'Editora'] = origin_row['Editora']\n",
    "#     ren.at[index, 'Código Coleção'] = origin_row['Código Coleção']\n",
    "#     ren.at[index, 'Coleção'] = origin_row['Coleção']\n",
    "#     ren.at[index, 'Código Volume'] = origin_row['Código Volume']\n",
    "#     ren.at[index, 'Volume'] = origin_row['Volume']\n",
    "#     ren.at[index, 'Componente'] = origin_row['Componente']\n",
    "#     ren.at[index, 'Série'] = origin_row['Série']\n",
    "#     ren.at[index, 'Formato'] = origin_row['Formato']\n",
    "#     ren.at[index, 'Exemplar'] = origin_row['Exemplar']\n",
    "#     ren.at[index, 'Tipo de Arquivo'] = origin_row['Tipo de Arquivo']\n",
    "#     ren.at[index, 'Arquivo'] = origin_row['Arquivo']\n",
    "#     ren.at[index, 'Header'] = origin_row['Header']\n",
    "#     #ren.at[index, 'Header get()'] = origin_row['Header get()']\n",
    "#     ren.at[index, 'Deve ser baixado'] = origin_row['Deve ser baixado']\n",
    "#     ren.at[index, 'Baixado'] = origin_row['Baixado']\n",
    "#     #ren.at[index, 'Extensão do Arquivo no Header'] = origin_row['Extensão do Arquivo no Header']\n",
    "#     ren.at[index, 'Integridade'] = origin_row['Integridade']\n",
    "#     ren.at[index, 'id_zip'] = i\n",
    "#     print(ren.at[index, 'Edital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sem_zip = ren[ren['Extensão do Arquivo'] != 'DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = m[(m['Extensão do Arquivo'] != 'zip') & (m['Extensão do Arquivo'] != 'x-zip-compressed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'pdf', 'docx', 'mp4', 'mp3', 'DOCX'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# m['Extensão do Arquivo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['docx', 'mp4', 'mp3', 'pdf', 'DOCX'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ren = ren[ren['Extensão do Arquivo'] != 'DS_Store']\n",
    "#m.loc[m['Extensão do Arquivo'] == 'DS_Store']\n",
    "\n",
    "# ren['Extensão do Arquivo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ren.to_csv('dados/DADOS_ZIP.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.to_csv('dados/DADOS_CRUZADOS.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def badly_zip_check (path, df, index):\n",
    "#     for root, dirs, files in os.walk(path):\n",
    "#         for file in files:\n",
    "#             if file.endswith('.zip'):\n",
    "#                 try:\n",
    "#                     zfile = zipfile.ZipFile(path + '/' + file)\n",
    "#                 except zipfile.BadZipfile as ex:\n",
    "#                     print (df.at[index, 'id'] + \" no a zip file: \" + ex)\n",
    "#                     df.at[index, 'Integridade'] = 'no a zip file'\n",
    "#                     continue\n",
    "\n",
    "#                 ret = zfile.testzip()\n",
    "\n",
    "#                 if ret is not None:\n",
    "#                     print (df.at[index, 'id'] + \" bad zip file, error: \" + ret)\n",
    "#                     df.at[index, 'Integridade'] = 'bad zip file'\n",
    "#                 else:\n",
    "#                     print (df.at[index, 'id'] + \" OK\")\n",
    "#                     df.at[index, 'Integridade'] = 'ok'\n",
    "                \n",
    "#                 df.to_csv('dados/TODOS.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unzip_all (df):\n",
    "#     for index, row in df.iterrows():\n",
    "#         if(row['Extensão do Arquivo'] in ['zip', 'x-zip-compressed']):\n",
    "# #             print (row['id'] + ' - ' + row['Edital'])\n",
    "# #             row['Nome do Arquivo']\n",
    "#             path = 'arquivos/' + row['Edital'] + '/zip/' + row['id']\n",
    "# #             path = row['id']\n",
    "            \n",
    "#             with zipfile.ZipFile(path + '/' + row['Nome do Arquivo'], \"r\") as zip_ref:\n",
    "#                 zip_ref.extractall(path)\n",
    "#             os.remove(path + '/' + row['Nome do Arquivo'])\n",
    "            \n",
    "#             df.at[index, 'Unzip'] = 'ok'\n",
    "\n",
    "# # unzip_all(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hahaha\n"
     ]
    }
   ],
   "source": [
    "# def verify_no_unzip (df):\n",
    "#     print('hahaha')\n",
    "#     for index, row in df.iterrows():\n",
    "#         if(row['Extensão do Arquivo'] in ['zip', 'x-zip-compressed'] and row['Unzip'] != 'ok'):\n",
    "#             print(row['id'])\n",
    "# verify_no_unzip(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arquivos/PNLD 2020 - Obras Didáticas - Anos Finais do Ensino Fundamental/3974\n",
      "3974 OK\n",
      "arquivos/PNLD 2020 - Obras Didáticas - Anos Finais do Ensino Fundamental/3990\n",
      "3990 OK\n",
      "arquivos/PNLD 2020 - Obras Didáticas - Anos Finais do Ensino Fundamental/4670\n",
      "4670 OK\n"
     ]
    }
   ],
   "source": [
    "# each_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arquivos/PNLD 2020 - Obras Didáticas - Anos Finais do Ensino Fundamental/3067no a zip file\n",
      "arquivos/PNLD 2020 - Obras Didáticas - Anos Finais do Ensino Fundamental/3974no a zip file\n",
      "arquivos/PNLD 2020 - Obras Didáticas - Anos Finais do Ensino Fundamental/3990no a zip file\n",
      "arquivos/PNLD 2020 - Obras Didáticas - Anos Finais do Ensino Fundamental/4670no a zip file\n"
     ]
    }
   ],
   "source": [
    "# for index, row in df.iterrows():\n",
    "#     if (row['Integridade'] != 'ok') and (row['Extensão do Arquivo'] in ['zip', 'x-zip-compressed']):\n",
    "#         path = 'arquivos/' + row['Edital'] + '/' + row['id']\n",
    "#         print (path + row['Integridade'])\n",
    "#         df.at[index, 'Baixado'] = 'Não'\n",
    "#         df.to_csv('dados/TODOS.csv', index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_all_file_sizes (df):\n",
    "#     for index, row in df.iterrows():\n",
    "#         if row['Baixado'] == 'Sim':\n",
    "#             path = 'arquivos/' + row['Edital'] + '/' + row['id']\n",
    "#             print(path);\n",
    "#             get_size_file_in_kb(path, df, index)\n",
    "\n",
    "\n",
    "# def get_size_file_in_kb(path, df, index):\n",
    "#     for root, dirs, files in os.walk(path):\n",
    "#         for file in files:\n",
    "#             if file.endswith('.zip'):\n",
    "#                 get_real_and_zipped_size_in_kb(path, df, index, file)\n",
    "#             else:\n",
    "#                 get_size_file_in_kb(path, df, index, file)\n",
    "\n",
    "# def get_size_file_in_kb(path, df, index, file):\n",
    "#     for root, dirs, files in os.walk(path):\n",
    "#         if file.endswith('.pdf'):\n",
    "#             valid_file = check_pdf_file(path + '/' + file)\n",
    "#             if (valid_file):\n",
    "#                 df.at[index, 'Integridade'] = 'ok'\n",
    "#                 print (df.at[index, 'id'] + \" - OK\")\n",
    "#             else:\n",
    "#                 df.at[index, 'Integridade'] = 'no a pdf file'\n",
    "#                 print (df.at[index, 'id'] + \" - BAD PDF\")\n",
    "#                 df.to_csv('dados/TODOS.csv', index = False)\n",
    "#                 continue\n",
    "                        \n",
    "#         file_obj = Path(path + '/' + file)\n",
    "#         size = file_obj.stat().st_size\n",
    "\n",
    "#         size_kb = float(size) / 1000  # kB\n",
    "#         print (df.at[index, 'id'] + \" - \" + str(size_kb))\n",
    "#         df.at[index, 'Size'] = size_kb\n",
    "#         df.to_csv('dados/TODOS.csv', index = False)\n",
    "\n",
    "#         print('\\n\\n')\n",
    "\n",
    "\n",
    "# def get_real_and_zipped_size_in_kb(path, df, index, file):\n",
    "#     try:\n",
    "#         zfile = zipfile.ZipFile(path + '/' + file)\n",
    "#         zipped_size = os.path.getsize(path + '/' + file)\n",
    "#     except zipfile.BadZipfile as ex:\n",
    "#         print (df.at[index, 'id'] + \" no a zip file: \" + ex)\n",
    "#         df.at[index, 'Integridade'] = 'no a zip file'\n",
    "#         continue\n",
    "#     except:\n",
    "\n",
    "#     #zip test\n",
    "#     ret = zfile.testzip()\n",
    "#     if ret is not None:\n",
    "#         print (df.at[index, 'id'] + \" bad zip file, error: \" + ret)\n",
    "#         df.at[index, 'Integridade'] = 'bad zip file'\n",
    "#     else:\n",
    "#         df.at[index, 'Integridade'] = 'ok'\n",
    "\n",
    "#     real_size = sum([zinfo.file_size for zinfo in zfile.filelist])\n",
    "#     real_size_kb = float(size) / 1000  # kB\n",
    "#     zipped_size_kb = float(zipped_size) / 1000  # kB\n",
    "\n",
    "#     print (df.at[index, 'id'] + \" - \" + str(zip_kb))\n",
    "#     df.at[index, 'Size'] = real_size_kb\n",
    "#     df.at[index, 'Zipped size'] = zipped_size_kb\n",
    "#     df.to_csv('dados/TODOS.csv', index = False)\n",
    "\n",
    "\n",
    "# def check_pdf_file(fullfile):\n",
    "#     with open(fullfile, 'rb') as f:\n",
    "#         try:\n",
    "#             pdf = PdfFileReader(f)\n",
    "#             info = pdf.getDocumentInfo()\n",
    "#             if info:\n",
    "#                 return True\n",
    "#             else:\n",
    "#                 return False\n",
    "#         except:\n",
    "#             return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def remove_corrupted_files():\n",
    "#     i = 0\n",
    "#     for index, row in df.iterrows():\n",
    "#         if (row['Integridade'] != 'ok'):\n",
    "#             file = 'arquivos/' + row['Edital'] + '/' + row['id'] + '/' + row['Nome do Arquivo']\n",
    "#             print(row['Edital'] + '/' + row['id'])\n",
    "#             print(row['Arquivo'])\n",
    "#             i = i + 1\n",
    "#             if os.path.exists(file):\n",
    "#                 os.remove(file)\n",
    "#                 print(\"Arquivo Removido\")\n",
    "#             else:\n",
    "#                 print(\"The file does not exist\")\n",
    "\n",
    "#             df.at[index, 'Baixado'] = 'Não'\n",
    "#             df.to_csv('dados/TODOS.csv', index = False)\n",
    "#             print('\\n\\n')\n",
    "    \n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def map_files_in_zips (df, arq_zip):\n",
    "#     i = 0\n",
    "#     for index, row in df.iterrows():\n",
    "#         if (row['Baixado'] == 'Sim') and (row['Extensão do Arquivo'] in ['zip', 'x-zip-compressed']):\n",
    "#             path = 'arquivos/' + row['Edital'] + '/' + row['id']\n",
    "# #             print(path);\n",
    "            \n",
    "#             i = get_all_files_in_zip(path, df, index, row['id'], arq_zip, i)\n",
    "\n",
    "\n",
    "# def get_all_files_in_zip(path, df, index, df_row_id, arq_zip, i):\n",
    "#     for root, dirs, files in os.walk(path):\n",
    "#         for file in files:\n",
    "#             if file.endswith('.zip'):\n",
    "#                 with zipfile.ZipFile(path + '/' + file, 'r') as zipObj:\n",
    "#                     listOfiles = zipObj.infolist()\n",
    "# #                     print(listOfiles)\n",
    "#                     for elem in listOfiles:\n",
    "#                         row = {}\n",
    "#                         row['red_id'] = df_row_id\n",
    "#                         row['nome'] = elem.filename.split(\"/\")[-1]\n",
    "#                         row['tamanho'] = elem.file_size\n",
    "#                         row['tamanho_zipado'] = elem.compress_size\n",
    "#                         row['extensão'] = elem.filename.split(\".\")[-1]\n",
    "#                         row['path'] = elem.filename\n",
    "#                         print(str(i) + ' - ', end=\"\")\n",
    "#                         print(row)\n",
    "#                         arq_zip.loc[i] = row\n",
    "#                         arq_zip.to_csv('dados/arquivos_zip.csv', index = False)\n",
    "        \n",
    "#                         i = i + 1\n",
    "#             else:\n",
    "#                 print('ERROR: ISNT ZIP')\n",
    "                \n",
    "#     return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_files_in_zips (df, arq_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n",
      "0360P20042_VONTADE_DE_SABER_HISTORIA_V7/\n",
      "334\n",
      "0360P20042_VONTADE_DE_SABER_HISTORIA_V8/\n",
      "429\n",
      "0379P20062_AUDIOVISUAIS_POR_TODA_PARTE_V9/\n",
      "464\n",
      "0386P20022_MATEMATICA_REALIDADE_E_TECNOLOGIA_V9/\n"
     ]
    }
   ],
   "source": [
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "    \n",
    "# for index, row in arq_zip.iterrows():\n",
    "#     if (row['extensão'] == 'DS'):\n",
    "#         print(index)\n",
    "#         print(row['extensão'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
